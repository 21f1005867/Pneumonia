{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11981792,"sourceType":"datasetVersion","datasetId":7535550},{"sourceId":12415621,"sourceType":"datasetVersion","datasetId":7830279}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import the importatnt libraries\nimport os\nimport numpy as np\nfrom torchvision import models\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split, Dataset\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nimport copy","metadata":{"trusted":true,"id":"SFvWvqV12z5Y","execution":{"iopub.status.busy":"2025-07-09T04:08:06.602318Z","iopub.execute_input":"2025-07-09T04:08:06.602569Z","iopub.status.idle":"2025-07-09T04:08:17.570432Z","shell.execute_reply.started":"2025-07-09T04:08:06.602548Z","shell.execute_reply":"2025-07-09T04:08:17.569753Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ignoring the warning messages\nimport warnings\nfrom IPython.display import display\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"id":"lCdYJ4672z5Z","execution":{"iopub.status.busy":"2025-07-09T04:08:17.571557Z","iopub.execute_input":"2025-07-09T04:08:17.571890Z","iopub.status.idle":"2025-07-09T04:08:17.575875Z","shell.execute_reply.started":"2025-07-09T04:08:17.571872Z","shell.execute_reply":"2025-07-09T04:08:17.575067Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"torch.manual_seed(42)\n# batch size for all the future processes\nbatch_size = 32","metadata":{"trusted":true,"id":"jpfyCjwg2z5Z","execution":{"iopub.status.busy":"2025-07-09T04:08:17.576674Z","iopub.execute_input":"2025-07-09T04:08:17.576948Z","iopub.status.idle":"2025-07-09T04:08:17.607924Z","shell.execute_reply.started":"2025-07-09T04:08:17.576925Z","shell.execute_reply":"2025-07-09T04:08:17.607398Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data = np.load(\"/kaggle/input/pneumoniamnist/pneumoniamnist.npz\")","metadata":{"trusted":true,"id":"8mYNVpeH2z5a","execution":{"iopub.status.busy":"2025-07-09T04:08:17.608727Z","iopub.execute_input":"2025-07-09T04:08:17.608998Z","iopub.status.idle":"2025-07-09T04:08:17.631709Z","shell.execute_reply.started":"2025-07-09T04:08:17.608974Z","shell.execute_reply":"2025-07-09T04:08:17.631234Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_images, train_labels = data[\"train_images\"], data[\"train_labels\"]","metadata":{"trusted":true,"id":"clDLZ0Rj2z5b","execution":{"iopub.status.busy":"2025-07-09T04:08:17.633354Z","iopub.execute_input":"2025-07-09T04:08:17.633966Z","iopub.status.idle":"2025-07-09T04:08:17.680291Z","shell.execute_reply.started":"2025-07-09T04:08:17.633944Z","shell.execute_reply":"2025-07-09T04:08:17.679789Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"val_images, val_labels = data[\"val_images\"], data[\"val_labels\"]","metadata":{"trusted":true,"id":"bd5krgcT2z5c","execution":{"iopub.status.busy":"2025-07-09T04:08:17.680839Z","iopub.execute_input":"2025-07-09T04:08:17.681101Z","iopub.status.idle":"2025-07-09T04:08:17.688378Z","shell.execute_reply.started":"2025-07-09T04:08:17.681073Z","shell.execute_reply":"2025-07-09T04:08:17.687723Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"test_images, test_labels = data[\"test_images\"], data[\"test_labels\"]","metadata":{"trusted":true,"id":"qPWY3fgY2z5d","execution":{"iopub.status.busy":"2025-07-09T04:08:17.689026Z","iopub.execute_input":"2025-07-09T04:08:17.689194Z","iopub.status.idle":"2025-07-09T04:08:17.711482Z","shell.execute_reply.started":"2025-07-09T04:08:17.689181Z","shell.execute_reply":"2025-07-09T04:08:17.710845Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_images.shape","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"1oiE5fGb2z5d","outputId":"1dcf272b-3f63-4ec5-dabf-05633cfbd5c1","execution":{"iopub.status.busy":"2025-07-09T04:08:17.712202Z","iopub.execute_input":"2025-07-09T04:08:17.712362Z","iopub.status.idle":"2025-07-09T04:08:17.726365Z","shell.execute_reply.started":"2025-07-09T04:08:17.712349Z","shell.execute_reply":"2025-07-09T04:08:17.725581Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(3882, 28, 28)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"train_labels.shape","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"RlIy5xcl2z5e","outputId":"e4b82451-ebc5-493b-fda9-d5f77bc1c3cc","execution":{"iopub.status.busy":"2025-07-09T04:08:17.727057Z","iopub.execute_input":"2025-07-09T04:08:17.727230Z","iopub.status.idle":"2025-07-09T04:08:17.744683Z","shell.execute_reply.started":"2025-07-09T04:08:17.727216Z","shell.execute_reply":"2025-07-09T04:08:17.744156Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(3882, 1)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"val_images.shape","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"tovpaBu62z5e","outputId":"72f35468-a807-463e-8983-517e1a0c34f8","execution":{"iopub.status.busy":"2025-07-09T04:08:17.745441Z","iopub.execute_input":"2025-07-09T04:08:17.746064Z","iopub.status.idle":"2025-07-09T04:08:17.763507Z","shell.execute_reply.started":"2025-07-09T04:08:17.746043Z","shell.execute_reply":"2025-07-09T04:08:17.762920Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(524, 28, 28)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"val_labels.shape","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"RFSpOLsb2z5f","outputId":"a0b5953f-acbd-4c73-d512-281797398c85","execution":{"iopub.status.busy":"2025-07-09T04:08:17.764066Z","iopub.execute_input":"2025-07-09T04:08:17.764252Z","iopub.status.idle":"2025-07-09T04:08:17.782062Z","shell.execute_reply.started":"2025-07-09T04:08:17.764232Z","shell.execute_reply":"2025-07-09T04:08:17.781442Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(524, 1)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"test_images.shape","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"7rMF33dM2z5f","outputId":"61437473-d6fd-42e6-888c-e64f86249f65","execution":{"iopub.status.busy":"2025-07-09T04:08:17.782686Z","iopub.execute_input":"2025-07-09T04:08:17.782867Z","iopub.status.idle":"2025-07-09T04:08:17.798071Z","shell.execute_reply.started":"2025-07-09T04:08:17.782853Z","shell.execute_reply":"2025-07-09T04:08:17.797425Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(624, 28, 28)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"test_labels.shape","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"x3_9YRzN2z5f","outputId":"e27ff45c-3b6f-408d-bc8f-c616cd29bda3","execution":{"iopub.status.busy":"2025-07-09T04:08:17.798706Z","iopub.execute_input":"2025-07-09T04:08:17.798866Z","iopub.status.idle":"2025-07-09T04:08:17.815016Z","shell.execute_reply.started":"2025-07-09T04:08:17.798853Z","shell.execute_reply":"2025-07-09T04:08:17.814418Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(624, 1)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n\n        # Convert image to torch tensor\n        image = torch.tensor(image, dtype=torch.float32)\n        label = torch.tensor(label, dtype=torch.float32)  # if using BCEWithLogitsLoss\n\n        # Ensure image has shape [1, H, W]\n        if image.ndim == 2:\n            image = image.unsqueeze(0)\n        elif image.ndim == 3 and image.shape[-1] in [1, 3]:\n            image = image.permute(2, 0, 1)\n\n        # Convert 1-channel grayscale to 3-channel RGB by repeating\n        if image.shape[0] == 1:\n            image = image.repeat(3, 1, 1)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n","metadata":{"id":"gAx7vJVg4DYl","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:17.817608Z","iopub.execute_input":"2025-07-09T04:08:17.817804Z","iopub.status.idle":"2025-07-09T04:08:17.832601Z","shell.execute_reply.started":"2025-07-09T04:08:17.817789Z","shell.execute_reply":"2025-07-09T04:08:17.831939Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# transform = transforms.Compose([\n#     transforms.Resize((299, 299)),         # Resize to match InceptionV3 input size\n#     transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # Normalize to [-1, 1] range (optional)\n# ])\n\n# transformations for the training datasets\ntransform = transforms.Compose([\n    transforms.Resize((384,384)), # resize the image according to the input size of the model\n    # transforms.Resize((224,224)),\n    transforms.RandomHorizontalFlip(p=0.3), # flip the image horizontally with probality of 0.3\n    transforms.RandomVerticalFlip(p=0.3), # flip the image vertically with probality of 0.3\n    transforms.CenterCrop(384), # crop the image from the center\n    transforms.RandomRotation(degrees=(-12, 12)),\n    transforms.RandomApply([transforms.ColorJitter(brightness=0.35, contrast=0.35, saturation=0.35, hue=0.2)], p=0.3), # apply random color jitter with probality of 0.3\n    transforms.RandomApply([transforms.RandomAffine(degrees=15, translate=(0.15, 0.15), scale=(0.85, 1.15))], p=0.4), # apply random affine transformation with probality of 0.4\n    transforms.RandomApply(([transforms.GaussianBlur(kernel_size=3)]), p=0.3), # apply random gaussian blur with probality of 0.3 #Change the kernel size according to the model not max 5\n    transforms.RandomErasing(p=0.3, scale=(0.02, 0.1), ratio=(0.3, 3.3)), # apply random erasing with probality of 0.3\n    # transforms.ToTensor(), # # Converts image to tensor and rescales to [0.0, 1.0]\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # normalize the image\n\n])","metadata":{"id":"bm-WNgdf91nl","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:17.833336Z","iopub.execute_input":"2025-07-09T04:08:17.833569Z","iopub.status.idle":"2025-07-09T04:08:17.853611Z","shell.execute_reply.started":"2025-07-09T04:08:17.833548Z","shell.execute_reply":"2025-07-09T04:08:17.853110Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"test_val_transforms = transforms.Compose([\n    transforms.Resize((480,480)), # resize the image according to the input size of the model\n    # transforms.Resize((224,224)),\n    transforms.CenterCrop(480),\n    # transforms.ToTensor(), # convert the image to tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # normalize the image\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:17.854211Z","iopub.execute_input":"2025-07-09T04:08:17.854384Z","iopub.status.idle":"2025-07-09T04:08:17.873743Z","shell.execute_reply.started":"2025-07-09T04:08:17.854370Z","shell.execute_reply":"2025-07-09T04:08:17.873272Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_dataset = ImageDataset(train_images, train_labels, transform=transform)\nval_dataset = ImageDataset(val_images, val_labels, transform=test_val_transforms)\ntest_dataset = ImageDataset(test_images, test_labels, transform=test_val_transforms)","metadata":{"id":"rdrI4abP4Ow3","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:17.874295Z","iopub.execute_input":"2025-07-09T04:08:17.874494Z","iopub.status.idle":"2025-07-09T04:08:17.889163Z","shell.execute_reply.started":"2025-07-09T04:08:17.874480Z","shell.execute_reply":"2025-07-09T04:08:17.888567Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Data loader\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n# Validation loader\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"trusted":true,"id":"l2xDggVT2z5f","execution":{"iopub.status.busy":"2025-07-09T04:08:17.889838Z","iopub.execute_input":"2025-07-09T04:08:17.890069Z","iopub.status.idle":"2025-07-09T04:08:17.909971Z","shell.execute_reply.started":"2025-07-09T04:08:17.890055Z","shell.execute_reply":"2025-07-09T04:08:17.909436Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers=4)","metadata":{"id":"XayoFQPt4cL4","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:17.910632Z","iopub.execute_input":"2025-07-09T04:08:17.910848Z","iopub.status.idle":"2025-07-09T04:08:17.927797Z","shell.execute_reply.started":"2025-07-09T04:08:17.910823Z","shell.execute_reply":"2025-07-09T04:08:17.927315Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, device, epoch, num_epochs, scheduler, threshold=0.5):\n    model.train()\n    running_loss = 0.0\n    num_correct_preds = 0.0\n    total_preds = 0.0\n    train_preds = []\n    train_labels = []\n\n    with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as tepoch:\n        for images, labels in train_loader:\n            images = images.to(device)\n            labels = labels.to(device).float().squeeze(1)  # âœ… shape: [B]\n\n            optimizer.zero_grad()\n\n            # InceptionV3 returns (main_output, aux_output)\n            main_output, aux_output = model(images)\n            main_output = main_output.squeeze(1)\n            aux_output = aux_output.squeeze(1)\n\n            loss_main = criterion(main_output, labels)\n            loss_aux = criterion(aux_output, labels)\n            loss = loss_main + 0.4 * loss_aux\n\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n            # Predictions\n            probs = torch.sigmoid(main_output)\n            preds = (probs > threshold).long()\n\n            train_preds.extend(preds.detach().cpu().numpy())\n            train_labels.extend(labels.detach().cpu().numpy())\n\n            num_correct_preds += (preds == labels.long()).sum().item()\n            total_preds += labels.size(0)\n\n            tepoch.set_postfix(\n                loss=running_loss / (tepoch.n + 1),\n                accuracy=f\"{(num_correct_preds / len(train_loader.dataset)) * 100:.2f}%\"\n            )\n            tepoch.update(1)\n\n    scheduler.step()\n\n    # ðŸ§® Compute evaluation metrics\n    precision = precision_score(train_labels, train_preds, average='weighted', zero_division=0)\n    recall = recall_score(train_labels, train_preds, average='weighted', zero_division=0)\n    f1 = f1_score(train_labels, train_preds, average='weighted', zero_division=0)\n    train_accuracy = (num_correct_preds / total_preds) * 100\n\n    print(f\"\\nTrain Metrics â€” Accuracy: {train_accuracy:.2f}% | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n\n    return train_accuracy, running_loss / len(train_loader), f1, precision, recall\n","metadata":{"id":"FYGCAtZS4yuC","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:17.928466Z","iopub.execute_input":"2025-07-09T04:08:17.928716Z","iopub.status.idle":"2025-07-09T04:08:17.950438Z","shell.execute_reply.started":"2025-07-09T04:08:17.928702Z","shell.execute_reply":"2025-07-09T04:08:17.949934Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def validate(model, val_loader, criterion, device, threshold=0.5):\n    model.eval()\n    running_loss = 0.0\n    num_correct_preds = 0.0\n    total_preds = 0.0\n    val_preds = []\n    val_labels = []\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device).float()  # âœ… Ensure shape [B]\n\n            outputs = model(images)  # shape: [batch_size]\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item()\n\n            probs = torch.sigmoid(outputs)\n            preds = (probs > threshold).long()\n\n            val_preds.extend(preds.cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n\n            num_correct_preds += (preds == labels.long()).sum().item()\n            total_preds += labels.size(0)\n\n    # ðŸ§® Compute metrics\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted', zero_division=0)\n    f1 = f1_score(val_labels, val_preds, average='weighted', zero_division=0)\n    val_accuracy = (num_correct_preds / total_preds) * 100\n\n    print(f\"\\nValidation Metrics â€” Accuracy: {val_accuracy:.2f}% | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n\n    return val_accuracy, running_loss / len(val_loader), f1, precision, recall\n","metadata":{"id":"fqgmFVF_7Kws","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:17.951333Z","iopub.execute_input":"2025-07-09T04:08:17.951530Z","iopub.status.idle":"2025-07-09T04:08:17.973829Z","shell.execute_reply.started":"2025-07-09T04:08:17.951516Z","shell.execute_reply":"2025-07-09T04:08:17.973134Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def training_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, scheduler, model_name, threshold=0.5):\n    best_f1 = 0.0\n    best_model = None\n\n    for epoch in range(num_epochs):\n        # ðŸ” Train the model\n        train_accuracy, train_loss, train_f1, train_precision, train_recall = train(\n            model, train_loader, val_loader, criterion, optimizer, device, epoch, num_epochs, scheduler, threshold=threshold\n        )\n\n        # ðŸ” Validate the model\n        val_accuracy, val_loss, val_f1, val_precision, val_recall = validate(\n            model, val_loader, criterion, device, threshold=threshold\n        )\n\n        # ðŸ’¾ Save the best model based on validation F1\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            best_model = copy.deepcopy(model.state_dict())\n            torch.save(best_model, f'best_model_{model_name}_epoch{epoch+1}.pth')\n\n            print(f'\\nâœ… Best model saved at epoch {epoch+1}/{num_epochs}')\n            print(f'   ðŸŸ¢ Train â€” Acc: {train_accuracy:.2f}%, Loss: {train_loss:.4f}, F1: {train_f1:.4f}, P: {train_precision:.4f}, R: {train_recall:.4f}')\n            print(f'   ðŸ”µ Val   â€” Acc: {val_accuracy:.2f}%, Loss: {val_loss:.4f}, F1: {val_f1:.4f}, P: {val_precision:.4f}, R: {val_recall:.4f}\\n')\n\n        torch.cuda.empty_cache()\n\n    return model, best_model\n","metadata":{"id":"wf4x5aRt5VrN","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:17.974489Z","iopub.execute_input":"2025-07-09T04:08:17.974688Z","iopub.status.idle":"2025-07-09T04:08:17.995698Z","shell.execute_reply.started":"2025-07-09T04:08:17.974665Z","shell.execute_reply":"2025-07-09T04:08:17.995222Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# using the pre-trained model with importing the pretrained weight efficente_v2_m\n# from torchvision.models import Inception_V3_Weights\nmodel = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)","metadata":{"id":"L0NkF5fD5dcW","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:17.996415Z","iopub.execute_input":"2025-07-09T04:08:17.996643Z","iopub.status.idle":"2025-07-09T04:08:19.092983Z","shell.execute_reply.started":"2025-07-09T04:08:17.996623Z","shell.execute_reply":"2025-07-09T04:08:19.092350Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104M/104M [00:00<00:00, 199MB/s]  \n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# InceptionV3\nmodel.fc = nn.Linear(model.fc.in_features, 1)\nmodel.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, 1)","metadata":{"id":"Ny2Odaxe500u","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:19.093754Z","iopub.execute_input":"2025-07-09T04:08:19.094095Z","iopub.status.idle":"2025-07-09T04:08:19.099202Z","shell.execute_reply.started":"2025-07-09T04:08:19.094071Z","shell.execute_reply":"2025-07-09T04:08:19.098601Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# for param in model.parameters():\n#     param.requires_grad = False  # Freeze all layers\n\n# # Unfreeze classifier layers\n# for param in model.fc.parameters():\n#     param.requires_grad = True\n\n# for param in model.AuxLogits.fc.parameters():\n#     param.requires_grad = True\n","metadata":{"id":"R0JfmUoXAZHk","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:19.100016Z","iopub.execute_input":"2025-07-09T04:08:19.100212Z","iopub.status.idle":"2025-07-09T04:08:19.115570Z","shell.execute_reply.started":"2025-07-09T04:08:19.100196Z","shell.execute_reply":"2025-07-09T04:08:19.114892Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model = nn.DataParallel(model, device_ids=[0, 1])  # Use GPUs 0 and 1\nmodel = model.to(device)","metadata":{"id":"FLG3cI8Z6XWX","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:19.116549Z","iopub.execute_input":"2025-07-09T04:08:19.116849Z","iopub.status.idle":"2025-07-09T04:08:19.463642Z","shell.execute_reply.started":"2025-07-09T04:08:19.116826Z","shell.execute_reply":"2025-07-09T04:08:19.462837Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# num_epochs = 15\nnum_epochs = 3\ncriterion = nn.BCEWithLogitsLoss()\n# optimizer = optim.NAdam(model.parameters(), lr=1e-4)\n# use the optimizer wiht SGD, momentum  and nestrov momentum\n# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, nesterov=True)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4)\n\n# scheduler for the learning rate\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.1e-6)\n# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n\nlast_epoch_model, best_model = training_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, scheduler, 'inception_v3', threshold=0.5)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfARXa7w7lmF","outputId":"0034a894-8134-46cc-a44d-980e2f3d9fd7","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:08:19.464649Z","iopub.execute_input":"2025-07-09T04:08:19.464967Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 58/122 [00:44<00:45,  1.40batch/s, accuracy=41.73%, loss=0.466]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/working/best_model_inception_v3_epoch1.pth'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_accuracy, val_loss, val_f1 = validate(\n            model, test_loader, criterion, device, threshold=0.5\n        )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}